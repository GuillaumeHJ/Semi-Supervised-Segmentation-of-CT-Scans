# Semi-Supervised Learning for CT-Scan Segmentation

This project was carried out as part of the **MVA Master's program at ENS Paris-Saclay**  
in the course taught by **StÃ©phane Mallat (CollÃ¨ge de France)**, in collaboration with **Raidium**.

It was also conducted in the context of the **ENS Data Challenge** on medical imaging.  
Our team ranked **8th out of 36 participants** on the final private leaderboard:  
ğŸ”— https://challengedata.ens.fr/participants/challenges/165/ranking/public

---

## ğŸ§  Project Motivation

CT scanners enable precise 3D visualization of internal anatomy, but annotations are often
incomplete and expensive to obtain. Our goal was to build a segmentation system that:

âœ… Learns from **partially labeled** images  
âœ… Leverages **unlabeled data** with semi-supervised methods  
âœ… Remains computationally feasible with limited GPU access

Total dataset: **2000 CT images**  
- **800 partially annotated**
- **1200 unlabeled**

This constraint modeled realistic clinical and industrial scenarios.

---

## ğŸ”¹ 1. Supervised Baseline (U-Net Variants)

We evaluated architectures used in medical imaging:

- âœ… **Attention U-Net (AttUNet)** â€“ best baseline
- MISSFormer
- UC-TransNet

To handle incomplete labels, we used **Dice Loss only** (without cross-entropy):

$$
\mathcal{L}_\text{Dice} = 1 - \frac{2 \cdot \sum_i P_i T_i}{\sum_i P_i + \sum_i T_i + \epsilon}
$$

**Best supervised result (AttUNet, 30 epochs):**  
ğŸ¯ Dice score: **0.27** (public leaderboard)

We also experimented with nnU-Net and DinoV2-based decoders, but compute limits prevented full convergence.

---

## ğŸ”¹ 2. Semi-Supervised Learning

To exploit the 1200 unlabeled scans, we implemented a **Teacher-Student framework**, inspired by \[Baldeon et al., 2023\]:

### âœ… Main Method: Teacherâ€“Student

1. **Teacher training** on labeled data (800 images)  
2. **Pseudo-label generation** for unlabeled data  
3. **Confidence-based filtering** â†’ keep 800 best pseudo-labels  
4. **Student training** with:
   - 800 labeled + 800 pseudo-labeled images
   - Loss = Dice + L2 consistency term

ğŸ“‰ Score improvement: **0.24 â†’ 0.25**  
This increase was marginal but measurable.

### ğŸ”„ Variants Explored

- Pretrain on pseudo-labels, then fine-tune
- Mean Teacher (EMA updates) â€” partial implementation

---

## ğŸ“Š Results & Training Dynamics

Training was constrained by GPU availability  
(Kaggle P100 GPU â†’ +10h per full run).

Here are the final learning curves for Teacherâ€“Student and Pretraining/Finetuning:

![](figs/SSL_TrainingCurves.png)

We observed:
- Slight gain in Dice during the second phase
- Limited impact due to:
  - Modest unlabeled data volume (1.5Ã— ratio)
  - Imperfect pseudo-label quality
  - Partial ground-truth masks
  - Limited hyperparameter tuning due to compute

---

## âœ… Repository Structure

```text
Sem-Supervised-Segmentation-of-CT-Scans/
â”œâ”€â”€ README.md
â”œâ”€â”€ REPORT.pdf
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ run.py
â”‚ â””â”€â”€ Raidium_Challenge_Data_2025_Exemple_Data_Handling.ipynb
```


---

## ğŸ… Competition Context

This project was evaluated as part of the  
**ENS Challenge Data - Medical Segmentation Task**, hosted by CollÃ¨ge de France and Raidium.

âœ… **Final ranking:** 8th / 36  
ğŸ”— https://challengedata.ens.fr/participants/challenges/165/ranking/public

---

## ğŸ“¥ Full Report

The complete written project (LaTeX/PDF) is available in:  
ğŸ“„ `REPORT.pdf`

It includes:
- Methodology
- Architectures
- Figures and curves
- Critical analysis
- Future extensions

---

## ğŸ‘¥ Contributors

- Guillaume Henon-Just & Emilie Pic 
  Master MVA, ENS Paris-Saclay  
  Course by StÃ©phane Mallat, CollÃ¨ge de France  
  Collaboration with Raidium

---

## ğŸ¯ Keywords

Medical Imaging Â· Semi-Supervised Learning Â· U-Net Â· Pseudo-Labeling Â· CT Scans Â· Dice Loss

---

Feel free to reach out for collaboration or research discussions.
